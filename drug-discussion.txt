After running each model 10 times, it was possible to better analyze the performance of the model. 
The Gaussian Naive Bayes, the Decision Trees and the Perceptron models have a consistent performance across all runs. 
In fact, their respective standard deviations for accuracy, macro-average F1 and weighted-average F1 are all 0 or extremely close to 0. However, the Multi-layer Perceptron models had a significant variation in performance across the runs. 
Altought, the numbers may seem small they are significant compared to the average of the Gaussian Naive Bayes, the Decision Trees and the Perceptron models.

This can be explained from the presence of randomness in the model's initialization. The Gaussian Naive Bayes and the Decision Trees do not depend on any random variable initialization. The probabilities and entropies are based on the given dataset. Thus, they are deterministic which explains the similar performance across runs. The Perceptron does contain a random variable on initialization which is the weights. Nonetheless, since it a simpler model, in the sense that it can only do linear classification problems, then it will reach the same results consistently. For the Multi-layer Perceptron models, since it is a network of neurons, upon initialization, there will be a greater amount of random values. Thus, there is a greater chance of variability in predictions. 