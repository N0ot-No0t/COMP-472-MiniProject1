{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Task 1 &mdash; Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the distribution of the instances in each class and save the graphic in a file called BBC-distribution.pdf.\n",
    "You may want to use matplotlib.pyplot and savefig to do this. This pre-analysis of the data set will\n",
    "allow you to determine if the classes are balanced, and which metric is more appropriate to use to evaluate\n",
    "the performance of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'sport', 'tech']\n",
      "[510 386 417 511 401]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = next(os.walk('BBC'))[1]\n",
    "nb_files_data = np.array([0]*len(next(os.walk('BBC'))[1]))\n",
    "\n",
    "for i in range(len(next(os.walk('BBC'))[1])):\n",
    "    _,_,files = next(os.walk(\"BBC/\"+labels[i]))\n",
    "    nb_files_data[i]=len(files)\n",
    "\n",
    "print(labels)\n",
    "print(nb_files_data)\n",
    "\n",
    "plt.xticks(range(len(nb_files_data)), labels)\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of articles')\n",
    "plt.title('Distribution of the BBC Articles')\n",
    "plt.bar(range(len(nb_files_data)), nb_files_data)\n",
    "#Comment this line below if you want to create the pdf file\n",
    "plt.show()\n",
    "#Uncomment this line below if you want to create the pdf file \n",
    "#plt.savefig(\"BBC-distribution.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the corpus using load files and make sure you set the encoding to latin1. This will read the file\n",
    "structure and assign the category name to each file from their parent directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_files(\"BBC\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-process the dataset to have the features ready to be used by a multinomial Naive Bayes classifier. This\n",
    "means that the frequency of each word in each class must be computed and stored in a term-document\n",
    "matrix. For this, you can use feature extraction.text.CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>000bn</th>\n",
       "      <th>000m</th>\n",
       "      <th>000s</th>\n",
       "      <th>000th</th>\n",
       "      <th>001</th>\n",
       "      <th>001and</th>\n",
       "      <th>001st</th>\n",
       "      <th>...</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zooropa</th>\n",
       "      <th>zornotza</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zubair</th>\n",
       "      <th>zuluaga</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zutons</th>\n",
       "      <th>zvonareva</th>\n",
       "      <th>zvyagintsev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 29126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  0001  000bn  000m  000s  000th  001  001and  001st  ...  zooms  \\\n",
       "0      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "1      0    2     0      0     0     0      0    0       0      0  ...      0   \n",
       "2      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "3      0    0     0      0     2     0      0    0       0      0  ...      0   \n",
       "4      0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "...   ..  ...   ...    ...   ...   ...    ...  ...     ...    ...  ...    ...   \n",
       "2220   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2221   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2222   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2223   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "2224   0    0     0      0     0     0      0    0       0      0  ...      0   \n",
       "\n",
       "      zooropa  zornotza  zorro  zubair  zuluaga  zurich  zutons  zvonareva  \\\n",
       "0           0         0      0       0        0       0       0          0   \n",
       "1           0         0      0       0        0       0       0          0   \n",
       "2           0         0      0       0        0       0       0          0   \n",
       "3           0         0      0       0        0       0       0          0   \n",
       "4           0         0      0       0        0       0       0          0   \n",
       "...       ...       ...    ...     ...      ...     ...     ...        ...   \n",
       "2220        0         0      0       0        0       0       0          0   \n",
       "2221        0         0      0       0        0       0       0          0   \n",
       "2222        0         0      0       0        0       0       0          0   \n",
       "2223        0         0      0       0        0       0       0          0   \n",
       "2224        0         0      0       0        0       0       0          0   \n",
       "\n",
       "      zvyagintsev  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "2220            0  \n",
       "2221            0  \n",
       "2222            0  \n",
       "2223            0  \n",
       "2224            0  \n",
       "\n",
       "[2225 rows x 29126 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "tdm = cv.fit_transform(data.data)\n",
    "df = pd.DataFrame(tdm.toarray(), columns=cv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Split the dataset into 80% for training and 20% for testing. For this, you must use train test split with\n",
    "the parameter random state set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_classes, test_classes = train_test_split(data.data, data.target, test_size=0.2, train_size=0.8, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train a multinomial Naive Bayes Classifier (naive bayes.MultinomialNB) on the training set using the\n",
    "default parameters and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(smoothing=None):\n",
    "    if smoothing != None:\n",
    "        model = MultinomialNB(alpha=smoothing)\n",
    "    else:\n",
    "        model = MultinomialNB()\n",
    "    model.fit(cv.transform(train_data), train_classes)\n",
    "    predictions = model.predict(cv.transform(test_data))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In a file called bbc-performance.txt, save the following information: (to make it easier for the TAs, make\n",
    "sure that your output for each sub-question below is clearly marked in your output file, using the headings\n",
    "(a), (b) . .. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-8-3fd02468dc28>:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  first_doc_of_class_index = 0 if index is 0 else first_doc_of_class_index + nb_files_data[index-1]\n"
     ]
    }
   ],
   "source": [
    "def generate_performance_file(title, predictions):\n",
    "    with open(\"bbc-performance.txt\", \"a\") as file:\n",
    "        #a)\n",
    "        file.write(\"**********************************************\\n\")\n",
    "        file.write(f\"*****{title}******\\n\")\n",
    "        file.write(\"**********************************************\\n\\n\")\n",
    "        #b)\n",
    "        cm = confusion_matrix(test_classes, predictions)\n",
    "        file.write(str(cm))\n",
    "        file.write(\"\\n\\n\")\n",
    "        #c)\n",
    "        results = classification_report(test_classes, predictions)\n",
    "        file.write(results)\n",
    "        #d)\n",
    "        file.write(f\"\\nAccuracy of model: {accuracy_score(test_classes, predictions)}\\n\")\n",
    "        file.write(f\"Macro-average F1: {f1_score(test_classes, predictions, average='macro')}\\n\")\n",
    "        file.write(f\"Weighted-average F1: {f1_score(test_classes, predictions, average='weighted')}\\n\\n\")\n",
    "        #e)\n",
    "        file.write(\"Prior probabilites:\\n\")\n",
    "        total_docs = sum(nb_files_data)\n",
    "        for index in range(len(labels)):\n",
    "            file.write(f\"P({labels[index]}) = {nb_files_data[index]/total_docs}\\n\")\n",
    "        #f)\n",
    "        vocab_size = len(cv.vocabulary_)\n",
    "        file.write(f\"\\nSize of vocabulary {vocab_size}\\n\")\n",
    "        #g)\n",
    "        document_word_array = tdm.toarray()\n",
    "        for index in range(len(labels)):\n",
    "            first_doc_of_class_index = 0 if index is 0 else first_doc_of_class_index + nb_files_data[index-1]\n",
    "            last_doc_of_class_index = first_doc_of_class_index + nb_files_data[index] - 1\n",
    "            file.write(f\"Number of word tokens in {labels[index]}: {sum(document_word_array[first_doc_of_class_index:last_doc_of_class_index+1].sum(axis=0))}\\n\")\n",
    "        #h)\n",
    "        file.write(f\"Number of word tokens in entire corpus: {sum(tdm.toarray().sum(axis=0))}\\n\")\n",
    "        #i)\n",
    "        #???\n",
    "        #j)\n",
    "        y = np.array(tdm.toarray())\n",
    "        num_words_frequency_1 = np.count_nonzero(y.sum(axis=0) == 1)\n",
    "        percent_words_frequency_1 = (num_words_frequency_1/vocab_size)*100\n",
    "        file.write(f\"Number of words with a frequency of 1: {num_words_frequency_1}\\n\")\n",
    "        file.write(f\"Percent of words with a frequency of 1: {percent_words_frequency_1}%\\n\")\n",
    "        #k)\n",
    "        #???\n",
    "        file.write(\"\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_performance_file(\"MultinomialNB default values, try 1\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Redo steps 6 and 7 without changing anything (do not redo step 5, the dataset split). Change the\n",
    "model name to something like “MultinomialNB default values, try 2” and append the results to the file\n",
    "bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_performance_file(\"MultinomialNB default values, try 2\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Redo steps 6 and 7 again, but this time, change the smoothing value to 0.0001. Append the results at the\n",
    "end of bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_smoothing = train(0.0001)\n",
    "generate_performance_file(\"MultinomialNB, 0.0001 smoothing\", predictions_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Redo steps 6 and 7, but this time, change the smoothing value to 0.9. Append the results at the end of\n",
    "bbc-performance.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_smoothing = train(0.9)\n",
    "generate_performance_file(\"MultinomialNB, 0.9 smoothing\", predictions_smoothing)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e830b2fca68cf615af0c7604ec709cb4462275e58d0ae0cb29efc85d96d56142"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
